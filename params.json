{"name":"Linda","tagline":"Lesion Identification with Neighborhood Data Analysis","body":"## What is LINDA?  \r\nIs a neuroimaging toolkit for automatic segmentation of  __chronic__ stroke lesions.   \r\n*****  \r\n##  Requirements:  \r\n* Linux or Mac (ANTsR cannot run in Windows yet)  \r\n* [R v3.0 or above](http://www.r-project.org/) \r\n* The [ANTsR](http://stnava.github.io/ANTsR/) package installed in R\r\n* A T1-weighted MRI of a patient with (left hemispheric) stroke\r\n \r\n*****  \r\n## Install:  \r\nDownload the [latest release](https://github.com/dorianps/LINDA/releases/download/0.2.1/LINDA_v0.2.1.zip) (v0.2.1, 580Mb) and unzip in a local folder.  \r\n  \r\n_IMPORTANT: Do not use the DOWNLOAD button you see on this page, it does not contain the full release (files are too large to put in Github repositories)._  \r\n  \r\n*****  \r\n## Run:  \r\nOpen R and source the file linda_predict.R\r\n`source('/data/myfolder/stroke/LINDA/linda_predict.R')`  \r\nA file dialog will allow you to select the T1 nifti file of the patient with left hemispheric brain damage.  \r\nLINDA will run and you will see the timestamp of the various steps.  \r\nResults will be saved in a folder named \"linda\" in the same path where the T1 is located.  \r\n\r\n  \r\n _Note, LINDA will stop if you don't have `ANTsR` installed, and will automatically install the `randomForest` package._  \r\n  \r\n  \r\n**Available prediction models:**  \r\n_Currently a model trained on 60 patients from Penn is used. The internal prediction engine works with 2mm voxel resolution. This does not mean your images need to be 2mm, any resolution should work._  \r\n  \r\n*****  \r\n## Example:  \r\n`source('/data/myfolder/stroke/LINDA/linda_predict.R')`  \r\n>  12:09 Starting LINDA v0.2.1 ...  \r\n12:09 Loading file: TMT_MPRAGE.nii  \r\n12:09 Creating folder: /data/jag/dp/LINDAtest/TMT/linda  \r\n12:09 Loading template...  \r\n12:09 Skull stripping... (long process)  \r\n12:34 Saving skull stripped files  \r\n12:34 Loading LINDA model  \r\n12:34 Computing asymmetry mask...  \r\n12:38 Saving asymmetry mask...  \r\n12:38 Running 1st registration...  \r\n12:45 Feature calculation...  \r\n12:50 Running 1st prediction...  \r\n12:51 Saving 1st prediction...   \r\n12:51 Backprojecting 1st prediction...  \r\n12:51 Running 2nd registration...  \r\n12:57 Feature calculation...  \r\n13:01 Running 2nd prediction...  \r\n13:02 Saving 2nd prediction...  \r\n13:02 Backprojecting 2nd prediction...  \r\n13:02 Running 3rd registration... (long process)  \r\n14:56 Saving 3rd registration results...  \r\n14:56 Feature calculation...  \r\n15:01 Running 3rd prediction...  \r\n15:02 Saving 3rd final prediction...  \r\n15:02 Saving 3rd final prediction in template space...  \r\n15:02 Saving 3rd final prediction in native space...  \r\n15:02 Saving probabilistic prediction in template space...  \r\n15:02 Saving probabilistic prediction in native space...  \r\n15:02 Transferring data in MNI space...  \r\n15:02 Saving subject in MNI space...  \r\n15:02 Saving lesion in MNI space...  \r\nDONE  \r\n  \r\n  \r\nWonder what to expect? Check individual results from our  [60 patients Penn dataset](https://drive.google.com/file/d/0BxHeqEv37qqDT085MHAyMzFJcVk) and [45 patients Georgetown dataset](https://drive.google.com/open?id=0BxHeqEv37qqDY1psaC14QXZSOXc).  \r\n  \r\n*****\r\n## OUTPUT files:  \r\n__BrainMask.nii.gz__ - Brain mask used to skull strip (native space)  \r\n__N4corrected.nii.gz__ - Bias corrected, full image (native space)  \r\n__N4corrected_Brain.nii.gz__ - Bias corrected, brain only (native space)  \r\n__N4corrected_Brain_LRflipped.nii.gz__ - Flipped image used to compute asymmetry mask (native space)  \r\n__Mask.lesion(1)(2)(3).nii.gz__ - masks used for registrations (native space)  \r\n__Prediction(1)(2)(3).nii.gz__ - lesion predictions after each iteration (template space, but 2mm)  \r\n__Prediction3_template.nii.gz__ - final prediction (template space)  \r\n__Prediction3_native.nii.gz__ - final prediction (native space)  \r\n__Prediction3_probability_template.nii.gz__ - final graded probability (template space)  \r\n__Prediction3_probability_native.nii.gz__ - final graded probability (native space)  \r\n__Reg3_registered_to_template.nii.gz__ - Subject's MRI, skull stripped, bias corrected, registered to template (template space)  \r\n__Reg3_sub_to_template_(affine)(warp)__ - transformation matrices to register subject to template  \r\n__Reg3_template_to_sub_(affine)(warp)__ - transformation matrices to backproject template to subject  \r\n__Subject_in_MNI.nii.gz__ - Subject's MRI, skull stripped, bias corrected, transformed in MNI space  \r\n__Lesion_in_MNI.nii.gz__ - Lesion mask in MNI space  \r\n  \r\n*****  \r\n## Frequently Asked Questions\r\n__- What file formats are accepted__?  \r\nNifti images (.nii and .nii.gz) are accepted. The platform can read many other formats, but we have limited the script to Nifti in order to avoid confusion with some formats (i.e., Analyze) that have unclear left-right orientation.  \r\n__- Can I use it with right hemispheric lesions?__  \r\nYes, but you need to flip the L-R orientation before. After that, the prediction will work just as well. We plan to extend the script in the future for use in both left and right lesions.  \r\n__- Can I use it with bilateral lesions?__  \r\nIt will likely be less accurate. One of the features we use is related to the left-right signal asymmetry  \r\n__- Can I use it to segment acute and subacute stroke lesions?__  \r\nNo, the current model is trained only on chronic stroke patients. It might be possible to segment acute stroke with models trained on acute data (let us know if you want to contribute with those data).  \r\n__- Can I use other images: FLAIR, T2, DWI?__  \r\nThe existing model uses only a T1, but we can adapt it with additional T2, FLAIR, DWI. We are open to collaborations with groups that have multimodal data and want to train LINDA with those. Having ~30 subjects is a good start.   \r\n__- Can I train a model with my own data?__  \r\nThis is perfectly doable, but we haven't made available the script online yet (needs some work to adapt it for widepsread use). If you are in a hurry, contact us and we will send the current version of the training script.  \r\n__- Can I use LINDA to obtain registrations in MNI?__  \r\nThe transfer in MNI is obtained by concatenating transformations \"Subject\" -> \"Penn Template\" -> \"ch2 MNI template\". Thus there are two sources of potential error. The second source of error is fixed for all subjects because our template has always the same registration on MNI. However, a fixed error is always an error. If you really want precise registration on MNI, we advise to register directly the subject to an MNI template (possibly using a group MNI template rather than the ch2).  \r\n  \r\n## Support:  \r\nThe best way to keep track of bugs or failures is to open a [New Issue](https://github.com/dorianps/LINDA/issues) on the Github system. You can also contact the author via email: dorian dot pustina at uphs dot upenn dot edu (translate from english). If the algorithm proceeds without errors but the automatic segmentation is erroneous, please send (i) your T1 image and (ii) the segmentation produced by LINDA in native space. Try also overlaying `Mask.lesion*.nii.gz` files on the T1 to check whether the brain mask is wrong somewhere.  \r\n  \r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}